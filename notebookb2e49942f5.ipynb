{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82198,"databundleVersionId":8968540,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Library","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics -q","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:54:19.465976Z","iopub.execute_input":"2024-08-16T14:54:19.466247Z","iopub.status.idle":"2024-08-16T14:54:34.541085Z","shell.execute_reply.started":"2024-08-16T14:54:19.466222Z","shell.execute_reply":"2024-08-16T14:54:34.539868Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os,os.path as osp\nfrom glob import glob\nfrom tqdm import tqdm\nimport shutil\nimport random\n\nimport cv2\nimport numpy as np\n\nfrom ultralytics import YOLO\nfrom ultralytics import settings\n\nimport yaml\nfrom sklearn.model_selection import train_test_split\n\nsettings.update({\"wandb\": False})","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:54:34.543266Z","iopub.execute_input":"2024-08-16T14:54:34.543596Z","iopub.status.idle":"2024-08-16T14:54:38.625375Z","shell.execute_reply.started":"2024-08-16T14:54:34.543559Z","shell.execute_reply":"2024-08-16T14:54:38.624406Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/vehicle-detection/TrafficPublic'\ntrain_dir = dataset_dir + '/train'\ntest_dir = dataset_dir + '/test'\nsave_dir = '/kaggle/working/yolov8'\nval_ratio = 0.2\n\n# Create folder dataset for yolov8\nos.makedirs(save_dir,exist_ok=True)\nos.makedirs(save_dir + '/' + 'images',exist_ok=True)\nos.makedirs(save_dir + '/' + 'labels',exist_ok=True)\n\nos.makedirs(save_dir + '/' + 'images/train',exist_ok=True)\nos.makedirs(save_dir + '/' + 'labels/train',exist_ok=True)\n\nos.makedirs(save_dir + '/' + 'images/val',exist_ok=True)\nos.makedirs(save_dir + '/' + 'labels/val',exist_ok=True)\n\n# List annotation file  \nann_paths = glob(osp.join(train_dir , '*.txt'))\nann_train, ann_val = train_test_split(ann_paths, test_size=val_ratio)\n\n# Copy train images and labels folder\nprint('Copy images and labels in train folder')\nfor ann_path in tqdm(ann_train):\n    filename = osp.split(ann_path[:-4])[-1]\n    \n    img_path = ann_path[0:-4] + '.jpg'\n    save_img_path = save_dir + '/images/train/' + filename + '.jpg'\n    save_label_path = save_dir + '/labels/train/' + filename + '.txt'\n    \n    if os.path.exists(img_path):  \n        shutil.copy(img_path, save_img_path)\n        shutil.copy(ann_path, save_label_path)\n\n# Copy val images and labels folder\nprint('Copy images and labels in val folder')\nfor ann_path in tqdm(ann_val):\n    filename = osp.split(ann_path[:-4])[-1]\n    \n    img_path = ann_path[0:-4] + '.jpg'\n    save_img_path = save_dir + '/images/val/' + filename + '.jpg'\n    save_label_path = save_dir + '/labels/val/' + filename + '.txt'\n    \n    if os.path.exists(img_path):  \n        shutil.copy(img_path, save_img_path)\n        shutil.copy(ann_path,  save_label_path)\n    \n# Create .yaml yolo format\nprint('Create config file dataset.yaml')\nclasses_list = []\nindex = 0\n\nfor label in open(train_dir + \"/classes.txt\", \"r\").read().split('\\n'): \n    classes_list.append(str(index) + ': ' + label)\n    index += 1\n    \ndata = {\n    \"path\" : save_dir,\n    \"train\" : save_dir + '/' + 'images/train',\n    \"val\" : save_dir + '/' + 'images/val',\n    \"names\" : classes_list\n}\n\nwith open('yolov8/dataset.yaml', 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False, sort_keys=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:54:38.626501Z","iopub.execute_input":"2024-08-16T14:54:38.626891Z","iopub.status.idle":"2024-08-16T14:54:55.191898Z","shell.execute_reply.started":"2024-08-16T14:54:38.626864Z","shell.execute_reply":"2024-08-16T14:54:55.190991Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Copy images and labels in train folder\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1459/1459 [00:11<00:00, 129.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Copy images and labels in val folder\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 365/365 [00:05<00:00, 71.75it/s] ","output_type":"stream"},{"name":"stdout","text":"Create config file dataset.yaml\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"model = YOLO('yolov8l.pt')  # load a pretrained model (recommended for training)\nresults = model.train(data='yolov8/dataset.yaml',project='detect',name = 'train', epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:54:55.193347Z","iopub.execute_input":"2024-08-16T14:54:55.193761Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt to 'yolov8l.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83.7M/83.7M [00:01<00:00, 46.3MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics YOLOv8.2.78 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.pt, data=yolov8/dataset.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=detect, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 4.02MB/s]\n2024-08-16 14:55:02,720\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-08-16 14:55:03,828\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=5\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5586655  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \nModel summary: 365 layers, 43,633,695 parameters, 43,633,679 gradients, 165.4 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir detect/train', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 20.1MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov8/labels/train... 1458 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1458/1458 [00:01<00:00, 1239.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov8/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov8/labels/val... 365 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 365/365 [00:00<00:00, 1156.30it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov8/labels/val.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mdetect/train\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/10      11.4G      1.999      2.414      1.721         91        640:  30%|â–ˆâ–ˆâ–ˆ       | 28/92 [00:23<00:49,  1.30it/s]","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"answer_list = []\n# Use the model\nmodel = YOLO('/kaggle/working/detect/train2/weights/best.pt')\n\nfor file in tqdm(glob(test_dir + '/*')):\n    \n    bbox_list = []\n    cls_list = []\n    scores_list = []\n\n    # Predict on an image\n    results = model(file, verbose=False)\n    # Process results list\n    for result in results:\n        \n        boxes = result.boxes\n        for box in boxes:\n            coor_box = box.xyxy.cpu().numpy().tolist()  # Boxes object for bounding box outputs\n            class_box = box.cls.cpu().numpy().tolist()\n            class_scores = box.conf.cpu().numpy().tolist()\n        \n            bbox_list.append(coor_box[0])\n            cls_list.append(int(class_box[0]))\n            scores_list.append(class_scores[0])\n        \n        value = (file.split('/')[-1], bbox_list, cls_list,scores_list )\n\n    answer_list.append(value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ncolumn_name = ['id','boxes', 'labels', 'scores']\nxml_df = pd.DataFrame(answer_list, columns=column_name)\nxml_df.to_csv('/kaggle/working/submission-pretrain_30_percent_finetune.csv', index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}